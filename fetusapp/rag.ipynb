{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from loguru import logger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the database schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_schema(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Fetch all table names in the database\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    schema = {}\n",
    "    for table in tables:\n",
    "        table_name = table[0]\n",
    "        # Get all column names for each table\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "        columns = [info[1] for info in cursor.fetchall()]\n",
    "        schema[table_name] = columns\n",
    "\n",
    "    conn.close()\n",
    "    return schema\n",
    "\n",
    "# Example usage:\n",
    "schema = get_database_schema('data.sqlite')\n",
    "schema_df = pd.DataFrame([(table, col) for table, cols in schema.items() for col in cols], columns=['Table', 'Column'])\n",
    "# schema['patients']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate openAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = os.path.join('..', 'keys.env')\n",
    "load_dotenv(dotenv_path)\n",
    "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-09 12:49:35.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_sql_query\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mOpenAI response:\n",
      "{\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"tokens\": {\n",
      "    \"prompt\": 958,\n",
      "    \"completion\": 51,\n",
      "    \"total\": 1009\n",
      "  },\n",
      "  \"cost\": \"$0.001539\"\n",
      "}\u001b[0m\n",
      "\u001b[32m2025-10-09 12:49:35.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_sql_query\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mGenerated SQL Query:\n",
      "SELECT id, first_name || ' ' || last_name\n",
      "FROM patients\n",
      "WHERE date_of_birth BETWEEN strftime('%Y-%m-%d', 'now', '-22 years') AND strftime('%Y-%m-%d', 'now', '-20 years');\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def generate_sql_query(user_query, schema, api_key):\n",
    "    \n",
    "    # Prepare the schema information as part of the system message\n",
    "    schema_prompt = \"Here is the database schema:\\n\"\n",
    "    for table, columns in schema.items():\n",
    "        schema_prompt += f\"Table: {table}\\nColumns: {', '.join(columns)}\\n\"\n",
    "    \n",
    "    # Use the Chat Completion API (for models like GPT-4)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a SQL expert specialized in SQLite. Based on the user's question and the following database schema, \"\n",
    "                \"generate only a valid SQL query. Ensure that Greek names remain in Greek, without transliteration. \"\n",
    "                \"Do not provide any explanations, comments, or additional context—only return the SQL query as plain text.\\n\"\n",
    "                \"When calculating dates or ages, make sure to use SQLite-compatible functions like strftime().\\n\\n\"\n",
    "                + schema_prompt\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User query: {user_query}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=150,\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "    )\n",
    "\n",
    "    sql_query = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Calculate cost\n",
    "    prompt_tokens = response.usage.prompt_tokens\n",
    "    completion_tokens = response.usage.completion_tokens\n",
    "\n",
    "    # GPT-3.5-turbo pricing per 1K tokens\n",
    "    input_cost = (prompt_tokens / 1000) * 0.0015\n",
    "    output_cost = (completion_tokens / 1000) * 0.002\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    response_dict = {\n",
    "        \"model\": response.model,\n",
    "        \"tokens\": {\n",
    "            \"prompt\": prompt_tokens,\n",
    "            \"completion\": completion_tokens,\n",
    "            \"total\": response.usage.total_tokens\n",
    "        },\n",
    "        \"cost\": f\"${total_cost:.6f}\",\n",
    "    }\n",
    "    logger.info(f\"OpenAI response:\\n{json.dumps(response_dict, indent=2, ensure_ascii=False)}\")\n",
    "    logger.info(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Extract the SQL query from the assistant's reply\n",
    "    sql_query = response.choices[0].message.content.strip()\n",
    "    # print(f\"Generated SQL Query: {sql_query}\") \n",
    "    return sql_query\n",
    "\n",
    "sql_query = generate_sql_query(\"Μια λίστα με τους πελάτες μου από 20 μέχρι 22 χρονών. Αριθμό πελάτη και ονοματεπώνυμο;\", schema, api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT id, first_name, last_name\\nFROM patients\\nWHERE (strftime('%Y', 'now') - strftime('%Y', date_of_birth)) BETWEEN 20 AND 22;\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(768, 'ΠΑΠΑΝΙΚΟΛΑΟΥ ΣΟΦΙΑ'), (910, 'ΑΝΔΡΟΜΑΧΗ ΠΕΤΡΟΥ'), (1170, 'ΝΤΟΣΤΗ ΣΟΝΙΑ'), (1171, 'ΣΥΝΝΕΦΑΚΗ ΒΑΣΙΛΙΚΗ'), (1288, 'ΜΕΛΙΝΑ ΠΑΝΤΑΖΟΠΟΥΛΟΥ'), (1323, 'ΕΡΡΙΚΑ ΝΟΥΣΗ'), (1417, 'ΝΑΧHIRE null'), (1467, 'ΒΑΣΙΛΕΙΑ ΤΖΕΛΕΠΗ'), (1468, 'ΒΑΣΙΛΕΙΑ ΤΖΕΛΕΠΗ')]\n"
     ]
    }
   ],
   "source": [
    "def execute_sql_query(sql_query, db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(sql_query)\n",
    "    result = cursor.fetchall()\n",
    "\n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "result = execute_sql_query(sql_query, db_path=\"data.sqlite\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-09 12:53:40.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msynthesize_response\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mOpenAI response:\n",
      "{\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"tokens\": {\n",
      "    \"prompt\": 349,\n",
      "    \"completion\": 15,\n",
      "    \"total\": 364\n",
      "  },\n",
      "  \"cost\": \"$0.000553\"\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the retrieved data, you have a total of 9 customers.\n"
     ]
    }
   ],
   "source": [
    "def synthesize_response(user_query, data, api_key):\n",
    "    \n",
    "    # Build a conversation prompt where the data retrieved from the database is included\n",
    "    data_context = f\"Retrieved data: {data}\\n\"\n",
    "\n",
    "    # Messages for the chat model (GPT-4) to synthesize the final response\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that provides concise and accurate answers based on user queries and retrieved data.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"User query: {user_query}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": data_context  # Provide the retrieved data as context for GPT-4\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        top_p=1,\n",
    "    )\n",
    "     # Calculate cost\n",
    "    prompt_tokens = response.usage.prompt_tokens\n",
    "    completion_tokens = response.usage.completion_tokens\n",
    "\n",
    "    # GPT-3.5-turbo pricing per 1K tokens\n",
    "    input_cost = (prompt_tokens / 1000) * 0.0015\n",
    "    output_cost = (completion_tokens / 1000) * 0.002\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    response_dict = {\n",
    "        \"model\": response.model,\n",
    "        \"tokens\": {\n",
    "            \"prompt\": prompt_tokens,\n",
    "            \"completion\": completion_tokens,\n",
    "            \"total\": response.usage.total_tokens\n",
    "        },\n",
    "        \"cost\": f\"${total_cost:.6f}\",\n",
    "    }\n",
    "    logger.info(f\"OpenAI response:\\n{json.dumps(response_dict, indent=2, ensure_ascii=False)}\")\n",
    "    \n",
    "    final_response = response.choices[0].message.content.strip()\n",
    "    return final_response\n",
    "\n",
    "# Example usage:\n",
    "final_response = synthesize_response(\"How many customers do I have?\", result, api_key=api_key)\n",
    "print(final_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_pipeline(user_query, db_path='data.sqlite', api_key=None):\n",
    "    # Step 1: Get the database schema dynamically\n",
    "    schema = get_database_schema(db_path)\n",
    "    # print(f\"Database Schema: {schema}\")  # Optional: to visualize the database schema\n",
    "    \n",
    "    # Step 2: Generate the SQL query from the user's natural language question\n",
    "    sql_query = generate_sql_query(user_query, schema, api_key)\n",
    "    # print(f\"Generated SQL Query: {sql_query}\")  # Optional: to visualize the generated SQL\n",
    "    \n",
    "    # Step 3: Execute the SQL query and retrieve data from the database\n",
    "    result = execute_sql_query(sql_query, db_path)\n",
    "    # print(f\"Retrieved Data: {result}\")  # Optional: to visualize the retrieved\n",
    "    \n",
    "    # Step 4: Synthesize the final response using GPT-4\n",
    "    final_response = synthesize_response(user_query, result, api_key)\n",
    "    \n",
    "    return final_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Μια λίστα με τους πελάτες μου από 20 μέχρι 22 χρονών.\"\n",
    "# user_query = \"Θέλω μια λίστα με τα duplicates με τους διπλούς πελάτες δίπλα στον αριθμό τους. Μπορείς να μου το δώσεις; Τα duplicates είναι άτομα με το ίδιο όνομα και επώνυμο. και θέλω τον αριθμό τους και το όνομα τους σε μορφή json; θέλω και τους δύο πελάτες που είναι duplicates να εμφανίζονται στην λίστα αλλά ο αριθμός τους να μη χρησιμοπποιείτε για την ανεύρεση των διπλοτύπων;\"\n",
    "\n",
    "response = rag_pipeline(user_query, db_path=\"data.sqlite\", api_key=api_key)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle the recursive question-answer process\n",
    "def ask_questions():\n",
    "    while True:\n",
    "        user_query = input(\"Enter your question (or type 'exit' to quit): \")\n",
    "        print(user_query)\n",
    "        \n",
    "        # Exit condition\n",
    "        if user_query.lower() == 'exit':\n",
    "            print(\"Exiting the question-answer loop.\")\n",
    "            break\n",
    "\n",
    "        # Process the query using your pipeline\n",
    "        response = rag_pipeline(user_query, db_path=\"data.sqlite\", api_key=api_key)\n",
    "        print(response)  # Print the response for the current query\n",
    "\n",
    "# Call the function to start the loop\n",
    "ask_questions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "tickers = [\"SPY\"]\n",
    "data = yf.download(tickers, period=\"max\", interval=\"1h\")\n",
    "print(data['Close'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "\n",
    "plot(data['Close'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fetusappenv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
